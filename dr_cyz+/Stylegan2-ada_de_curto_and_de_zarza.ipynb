{"cells":[{"cell_type":"markdown","source":["PAC. Pràctica 2. Tipologia i cicle de vida de les dades. Universitat Oberta de Catalunya.\n","\n","J. de Curtò i DíAz & I. de Zarzà i Cubero. decurto@uoc.edu dezarza@uoc.edu"],"metadata":{"id":"rmAg8fCrzmi5"}},{"cell_type":"markdown","metadata":{"id":"cPI5E5y0pujD"},"source":["# StyleGan2-ADA trained on data from NASA Perseverance\n","\n","<p align=\"center\">\n","    <a\n","    href=\"https://github.com/decurtoidiaz/drcyz\"\n","    target=\"_blank\"\n","    rel=\"noopener noreferrer\">\n","        <img\n","        alt=\"Neural Mars: Dr CyZ\"\n","        width=\"450\" height=\"450\"\n","        src=\"https://github.com/decurtoidiaz/drcyz/blob/main/dr_cyz+.png?raw=true\">\n","    </a>\n","</p>\n","\n","\n","\n"]},{"cell_type":"markdown","source":["StyleGan2-ADA trained on a subset of images from NASA Perseverance (DrCyZ).\n","\n","Adapt folder paths accordingly. Data is available at:\n","\n","CyZ: MARS Space Exploration Dataset.\n","\n","https://github.com/decurtoidiaz/cyz\n","\n","DrCyZ: Techniques for analyzing and extracting useful information from CyZ.\n","\n","https://github.com/decurtoidiaz/drcyz\n","\n","c@decurto.be z@dezarza.be"],"metadata":{"id":"rz6EpLHizpIc"}},{"cell_type":"markdown","source":["Original source code from:\n","\n","https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Stylegan2_ada_Custom_Training.ipynb\n","\n","adapted and modified by De Curtò i DíAz & De Zarzà i Cubero."],"metadata":{"id":"8bQXZNi81w1Z"}},{"cell_type":"markdown","metadata":{"id":"ktqaMJUZuOl7"},"source":["1.   [Install StyleGAN2-ADA on your Google Drive](#scrollTo=5YcUMPQp6ipP)\n","2.   [Train a custom model](#scrollTo=Ti11YiPAiQpb)\n","3.   [Generate images from pre-trained model](#scrollTo=f0A9ZNtferpk)\n","4.   [Latent space exploration](#scrollTo=5yG1UyHXXqsO)\n"]},{"cell_type":"markdown","metadata":{"id":"5YcUMPQp6ipP"},"source":["## Install StyleGAN2-ADA on your Google Drive"]},{"cell_type":"markdown","metadata":{"id":"SI_i1MwgpzOD"},"source":["StyleGAN2-ADA only works with Tensorflow 1. Run the next cell before anything else to make sure we’re using TF1 and not TF2.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1640960853600,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":-480},"id":"iKYAU7Wub3WW","outputId":"ed2255ea-3876-4149-937e-5f3aa92918bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n","Fri Dec 31 14:27:33 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["%tensorflow_version 1.x\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"19_1uXab3gND"},"source":["Then, mount your Drive to the Colab notebook: "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27178,"status":"ok","timestamp":1640960886806,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":-480},"id":"pxxYlEKI9Gis","outputId":"a4e7fb8f-0541-42f5-e29a-0b68873d7e80"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","from pathlib import Path\n","\n","content_path = Path('/').absolute() / 'content'\n","drive_path = content_path / 'drive'\n","drive.mount(str(drive_path))"]},{"cell_type":"markdown","metadata":{"id":"epV6TDzAjox1"},"source":["Finally, run this cell to install StyleGAN2-ADA on your Drive. If you’ve already installed the repository, it will skip the installation process and only check for updates. If you haven’t installed it, it will install all the necessary files. Beside, **in**, **out**, **datasets** and **training** folders are generated for data storage. Everything will be available on your Google Drive in the folder **StyleGAN2-ADA** even after closing this Notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":536,"status":"ok","timestamp":1640960894302,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":-480},"id":"8HX77jscX2zV","outputId":"77e7aa54-7431-44a0-ebbd-c5eb73bf6bf9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/StyleGAN2-ADA\n"]}],"source":["stylegan2_repo_url  = 'https://github.com/dvschultz/stylegan2-ada' # or https://github.com/NVlabs/stylegan2-ada\n","project_path        = drive_path / 'MyDrive' / 'StyleGAN2-ADA'\n","stylegan2_repo_path = project_path / 'stylegan2-ada'\n","\n","# Create project folder if inexistant\n","if not project_path.is_dir():\n","    %mkdir \"{project_path}\"\n","%cd \"{project_path}\"\n","\n","for dir in ['in', 'out', 'datasets', 'training']:\n","    if not (project_path / dir).is_dir():\n","        %mkdir {dir}\n","if not (project_path / 'datasets' / 'source').is_dir():\n","    %mkdir \"{project_path / 'datasets' / 'source'}\"\n","\n"," Download StyleGAN2-ada\n","!git config --global user.name \"ArthurFDLR\"\n","!git config --global user.email \"arthfind@gmail.com\"\n","if stylegan2_repo_path.is_dir():\n","    !git -C \"{stylegan2_repo_path}\" fetch origin\n","    !git -C \"{stylegan2_repo_path}\" checkout origin/main -- *.py\n","else:\n","    print(\"Install StyleGAN2-ADA\")\n","    !git clone {stylegan2_repo_url}"]},{"cell_type":"markdown","metadata":{"id":"Ti11YiPAiQpb"},"source":["## Train a custom model"]},{"cell_type":"markdown","metadata":{"id":"ioqYi9NzkUfG"},"source":["Once you have installed StyleGAN2-ADA on your Google Drive and set up the working directory, you can upload your training dataset images in the associated folder."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1640960899689,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":-480},"id":"OlV5HIEqiZvu","outputId":"35874af4-35ac-4a78-bb49-61b6394e3ebd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Upload your images dataset as /content/drive/MyDrive/StyleGAN2-ADA/datasets/source/dr_cyz.zip\n"]}],"source":["dataset_name = 'dr_cyz'\n","datasets_source_path = project_path / 'datasets' / 'source' / (dataset_name + '.zip')\n","if datasets_source_path.is_dir():\n","    print(\"Dataset ready for import.\")\n","else:\n","    print('Upload your images dataset as {}'.format(datasets_source_path))"]},{"cell_type":"markdown","metadata":{"id":"-y1-tvr5617d"},"source":["Unfortunately, large datasets might exceed the Google Drive quota after a few training batches. Indeed, StyleGAN2 download datasets multiple times during training. You might have to import your dataset in the local storage session. However, large files cannot be copy/paste from Drive *(Input/Output error)*. \n","\n","Run this cell to download your zipped dataset from your Drive and unzip it in the local session."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10573,"status":"ok","timestamp":1640960914765,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":-480},"id":"eQZGo4g5y7rh","outputId":"5ce706f9-1ac5-472c-ead1-86a0b91f3ba6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Importing dataset...\n","Zip file succesfuly imported\n","Extraction completed\n"]}],"source":["local_dataset_path = content_path / 'dataset'\n","if not local_dataset_path.is_dir():\n","    print(\"Importing dataset...\")\n","    %mkdir \"{local_dataset_path}\"\n","    %cp -a \"{project_path / 'datasets' / 'source' / (dataset_name + '.zip')}\" \"{local_dataset_path}\"\n","    print(\"Zip file succesfuly imported\")\n","else:\n","    print('Zip file allready imported')\n","\n","import zipfile\n","with zipfile.ZipFile(str(local_dataset_path / (dataset_name + '.zip')), 'r') as zip_ref:\n","    zip_ref.extractall(str(local_dataset_path))\n","print('Extraction completed')"]},{"cell_type":"markdown","metadata":{"id":"HeS9tDvt61VG"},"source":["### Convert dataset to .tfrecords"]},{"cell_type":"markdown","metadata":{"id":"_Q58MJbckLUc"},"source":["Next, we need to convert our image dataset to a format that StyleGAN2-ADA can read:`.tfrecords`.\n","\n","This can take a while."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269696,"status":"ok","timestamp":1640961194265,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":-480},"id":"IjH8kBDo3kFP","outputId":"0a13d9c2-5ef8-425b-858b-4f8d2705d27a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n","Suggested packages:\n","  fonts-noto ghostscript-x imagemagick-doc autotrace cups-bsd | lpr | lprng\n","  enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer povray radiance\n","  sane-utils texlive-base-bin transfig ufraw-batch inkscape libjxr-tools\n","  libwmf0.2-7-gtk poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n","  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n","  fonts-arphic-uming fonts-nanum\n","The following NEW packages will be installed:\n","  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts imagemagick\n","  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n","  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n","  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n","  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n","0 upgraded, 23 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 18.4 MB of archives.\n","After this operation, 66.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.12 [60.3 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [1,621 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [292 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [51.3 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6.q16 amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [423 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [14.2 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre-text all 3.5.27.1-8ubuntu0.4 [49.4 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre21 amd64 3.5.27.1-8ubuntu0.4 [561 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwmf0.2-7 amd64 0.2.8.4-12 [150 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.12 [62.4 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnetpbm10 amd64 2:10.0-15.3build1 [58.0 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 netpbm amd64 2:10.0-15.3build1 [1,017 kB]\n","Fetched 18.4 MB in 0s (45.8 MB/s)\n","Selecting previously unselected package fonts-droid-fallback.\n","(Reading database ... 155222 files and directories currently installed.)\n","Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n","Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Selecting previously unselected package liblqr-1-0:amd64.\n","Preparing to unpack .../01-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n","Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n","Selecting previously unselected package imagemagick-6-common.\n","Preparing to unpack .../02-imagemagick-6-common_8%3a6.9.7.4+dfsg-16ubuntu6.12_all.deb ...\n","Unpacking imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libmagickcore-6.q16-3:amd64.\n","Preparing to unpack .../03-libmagickcore-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libmagickwand-6.q16-3:amd64.\n","Preparing to unpack .../04-libmagickwand-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package poppler-data.\n","Preparing to unpack .../05-poppler-data_0.4.8-2_all.deb ...\n","Unpacking poppler-data (0.4.8-2) ...\n","Selecting previously unselected package fonts-noto-mono.\n","Preparing to unpack .../06-fonts-noto-mono_20171026-2_all.deb ...\n","Unpacking fonts-noto-mono (20171026-2) ...\n","Selecting previously unselected package libcupsimage2:amd64.\n","Preparing to unpack .../07-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n","Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n","Selecting previously unselected package libijs-0.35:amd64.\n","Preparing to unpack .../08-libijs-0.35_0.35-13_amd64.deb ...\n","Unpacking libijs-0.35:amd64 (0.35-13) ...\n","Selecting previously unselected package libjbig2dec0:amd64.\n","Preparing to unpack .../09-libjbig2dec0_0.13-6_amd64.deb ...\n","Unpacking libjbig2dec0:amd64 (0.13-6) ...\n","Selecting previously unselected package libgs9-common.\n","Preparing to unpack .../10-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n","Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Selecting previously unselected package libgs9:amd64.\n","Preparing to unpack .../11-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n","Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Selecting previously unselected package ghostscript.\n","Preparing to unpack .../12-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n","Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Selecting previously unselected package gsfonts.\n","Preparing to unpack .../13-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n","Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n","Selecting previously unselected package imagemagick-6.q16.\n","Preparing to unpack .../14-imagemagick-6.q16_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package imagemagick.\n","Preparing to unpack .../15-imagemagick_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking imagemagick (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libcupsfilters1:amd64.\n","Preparing to unpack .../16-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n","Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Selecting previously unselected package libdjvulibre-text.\n","Preparing to unpack .../17-libdjvulibre-text_3.5.27.1-8ubuntu0.4_all.deb ...\n","Unpacking libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n","Selecting previously unselected package libdjvulibre21:amd64.\n","Preparing to unpack .../18-libdjvulibre21_3.5.27.1-8ubuntu0.4_amd64.deb ...\n","Unpacking libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n","Selecting previously unselected package libwmf0.2-7:amd64.\n","Preparing to unpack .../19-libwmf0.2-7_0.2.8.4-12_amd64.deb ...\n","Unpacking libwmf0.2-7:amd64 (0.2.8.4-12) ...\n","Selecting previously unselected package libmagickcore-6.q16-3-extra:amd64.\n","Preparing to unpack .../20-libmagickcore-6.q16-3-extra_8%3a6.9.7.4+dfsg-16ubuntu6.12_amd64.deb ...\n","Unpacking libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Selecting previously unselected package libnetpbm10.\n","Preparing to unpack .../21-libnetpbm10_2%3a10.0-15.3build1_amd64.deb ...\n","Unpacking libnetpbm10 (2:10.0-15.3build1) ...\n","Selecting previously unselected package netpbm.\n","Preparing to unpack .../22-netpbm_2%3a10.0-15.3build1_amd64.deb ...\n","Unpacking netpbm (2:10.0-15.3build1) ...\n","Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Setting up imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n","Setting up poppler-data (0.4.8-2) ...\n","Setting up libdjvulibre-text (3.5.27.1-8ubuntu0.4) ...\n","Setting up libnetpbm10 (2:10.0-15.3build1) ...\n","Setting up fonts-noto-mono (20171026-2) ...\n","Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n","Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n","Setting up libjbig2dec0:amd64 (0.13-6) ...\n","Setting up libijs-0.35:amd64 (0.35-13) ...\n","Setting up netpbm (2:10.0-15.3build1) ...\n","Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Setting up libwmf0.2-7:amd64 (0.2.8.4-12) ...\n","Setting up libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.4) ...\n","Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Setting up libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n","update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n","update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n","update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n","update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n","update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n","update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n","update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n","update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n","update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n","update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n","update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n","update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n","update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n","update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n","update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n","update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n","update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n","update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n","update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n","update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n","update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n","Setting up libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Setting up imagemagick (8:6.9.7.4+dfsg-16ubuntu6.12) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Loading images from \"/content/dataset/dr_c_y_z_256\"\n","Creating dataset \"/content/dataset/tfr_256\"\n","/content/drive/MyDrive/StyleGAN2-ADA/stylegan2-ada/dataset_tool.py:97: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n","  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n","Added 5025 images.\n"]}],"source":["local_original_images_path = local_dataset_path / 'c' \n","local_images_path = local_dataset_path / 'dr_c_y_z_256'\n","local_dataset_path /= 'tfr_256'\n","!apt install imagemagick\n","\n","if (local_dataset_path).is_dir():\n","    print('\\N{Heavy Exclamation Mark Symbol} Dataset already created \\N{Heavy Exclamation Mark Symbol}')\n","    print('Delete current dataset folder ({}) to regenerate tfrecords.'.format(local_dataset_path))\n","else:\n","    %mkdir \"{local_images_path}\"\n","    !mogrify -path \"{local_images_path}\" -resize 256x256! \"{local_original_images_path / '*.png'}\"\n","    %mkdir \"{local_dataset_path}\"\n","    !python \"{stylegan2_repo_path / 'dataset_tool.py'}\" create_from_images \\\n","        \"{local_dataset_path}\" \"{local_images_path}\""]},{"cell_type":"markdown","metadata":{"id":"8DvTupHzP2s_"},"source":["There are numerous arguments to tune the training of your model. To obtain nice results, you will certainly have to experiment. Here are the most popular parameters:\n","\n","\n","*   *mirror:* Should the images be mirrored vertically?\n","*   *mirrory:* Should the images be mirrored horizontally?\n","*   *snap:* How often should the model generate image samples and a network pickle (.pkl file)?\n","*   *resume:* Network pickle to resume training from?\n","\n","To see all the options, run the following ```help``` cell.\n","\n","Please note that Google Colab Pro gives access to V100 GPUs, which drastically decreases (~3x) processing time over P100 GPUs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5195,"status":"ok","timestamp":1640961537816,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":-480},"id":"Fxu7CA0Qb1Yd","outputId":"260f76e3-5be2-4f37-ef16-faf66c4c1991"},"outputs":[{"name":"stdout","output_type":"stream","text":["usage: train.py [-h] --outdir DIR [--gpus INT] [--snap INT] [--seed INT] [-n]\n","                --data PATH [--res INT] [--mirror BOOL] [--mirrory BOOL]\n","                [--use-raw BOOL] [--metrics LIST] [--metricdata PATH]\n","                [--cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}]\n","                [--lrate FLOAT] [--ttur BOOL] [--gamma FLOAT] [--nkimg INT]\n","                [--kimg INT] [--topk FLOAT] [--aug {noaug,ada,fixed,adarv}]\n","                [--p FLOAT] [--target TARGET] [--initstrength INITSTRENGTH]\n","                [--augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}]\n","                [--cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}]\n","                [--dcap FLOAT] [--resume RESUME] [--freezed INT]\n","\n","Train a GAN using the techniques described in the paper\n","\"Training Generative Adversarial Networks with Limited Data\".\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","\n","general options:\n","  --outdir DIR          Where to save the results (required)\n","  --gpus INT            Number of GPUs to use (default: 1 gpu)\n","  --snap INT            Snapshot interval (default: 50 ticks)\n","  --seed INT            Random seed (default: 1000)\n","  -n, --dry-run         Print training options and exit\n","\n","training dataset:\n","  --data PATH           Training dataset path (required)\n","  --res INT             Dataset resolution (default: highest available)\n","  --mirror BOOL         Augment dataset with x-flips (default: false)\n","  --mirrory BOOL        Augment dataset with y-flips (default: false)\n","  --use-raw BOOL        Use raw image dataset, i.e. created from\n","                        create_from_images_raw (default: False)\n","\n","metrics:\n","  --metrics LIST        Comma-separated list or \"none\" (default: fid50k_full)\n","  --metricdata PATH     Dataset to evaluate metrics against (optional)\n","\n","base config:\n","  --cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}\n","                        Base config (default: auto)\n","  --lrate FLOAT         Override learning rate\n","  --ttur BOOL           Use Two Time-Scale Update Rule (double learning rate\n","                        for discriminator) (default: false)\n","  --gamma FLOAT         Override R1 gamma\n","  --nkimg INT           Override starting count\n","  --kimg INT            Override training duration\n","  --topk FLOAT          utilize top-k training\n","\n","discriminator augmentation:\n","  --aug {noaug,ada,fixed,adarv}\n","                        Augmentation mode (default: ada)\n","  --p FLOAT             Specify augmentation probability for --aug=fixed\n","  --target TARGET       Override ADA target for --aug=ada and --aug=adarv\n","  --initstrength INITSTRENGTH\n","                        Override ADA strength at start\n","  --augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}\n","                        Augmentation pipeline (default: bgc)\n","\n","comparison methods:\n","  --cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}\n","                        Comparison method (default: nocmethod)\n","  --dcap FLOAT          Multiplier for discriminator capacity\n","\n","transfer learning:\n","  --resume RESUME       Resume from network pickle (default: noresume)\n","  --freezed INT         Freeze-D (default: 0 discriminator layers)\n","\n","examples:\n","\n","  # Train custom dataset using 1 GPU.\n","  python train.py --outdir=~/training-runs --gpus=1 --data=~/datasets/custom\n","\n","  # Train class-conditional CIFAR-10 using 2 GPUs.\n","  python train.py --outdir=~/training-runs --gpus=2 --data=~/datasets/cifar10c \\\n","      --cfg=cifar\n","\n","  # Transfer learn MetFaces from FFHQ using 4 GPUs.\n","  python train.py --outdir=~/training-runs --gpus=4 --data=~/datasets/metfaces \\\n","      --cfg=paper1024 --mirror=1 --resume=ffhq1024 --snap=10\n","\n","  # Reproduce original StyleGAN2 config F.\n","  python train.py --outdir=~/training-runs --gpus=8 --data=~/datasets/ffhq \\\n","      --cfg=stylegan2 --res=1024 --mirror=1 --aug=noaug\n","\n","available base configs (--cfg):\n","  auto           Automatically select reasonable defaults based on resolution\n","                 and GPU count. Good starting point for new datasets.\n","  stylegan2      Reproduce results for StyleGAN2 config F at 1024x1024.\n","  paper256       Reproduce results for FFHQ and LSUN Cat at 256x256.\n","  paper512       Reproduce results for BreCaHAD and AFHQ at 512x512.\n","  paper1024      Reproduce results for MetFaces at 1024x1024.\n","  cifar          Reproduce results for CIFAR-10 (tuned configuration).\n","  cifarbaseline  Reproduce results for CIFAR-10 (baseline configuration).\n","\n","transfer learning source networks (--resume):\n","  ffhq256        FFHQ trained at 256x256 resolution.\n","  ffhq512        FFHQ trained at 512x512 resolution.\n","  ffhq1024       FFHQ trained at 1024x1024 resolution.\n","  celebahq256    CelebA-HQ trained at 256x256 resolution.\n","  lsundog256     LSUN Dog trained at 256x256 resolution.\n","  afhqcat512     AFHQ Cat trained at 512x512 resolution.\n","  afhqdog512     AFHQ Dog trained at 512x512 resolution.\n","  afhqwild512    AFHQ Wild trained at 512x512 resolution.\n","  brecahad512    BreCaHAD trained at 512x512 resolution.\n","  cifar10        CIFAR10 trained at 32x32 resolution.\n","  metfaces512    MetFaces trained at 512x512 resolution.\n","  <path or URL>  Custom network pickle.\n"]}],"source":["!python \"{stylegan2_repo_path / 'train.py'}\" --help"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOftFoyiDU3s","outputId":"fe7e4c3e-cd75-404d-e509-2d6f18c69bd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["tcmalloc: large alloc 4294967296 bytes == 0x55edabd04000 @  0x7fe6f1f84001 0x7fe6ef18754f 0x7fe6ef1d7b58 0x7fe6ef1dbb17 0x7fe6ef27a203 0x55eda5125544 0x55eda5125240 0x55eda5199627 0x55eda5193ced 0x55eda512748c 0x55eda5168159 0x55eda51650a4 0x55eda5125d49 0x55eda519994f 0x55eda51939ee 0x55eda5065e2b 0x55eda5195fe4 0x55eda51939ee 0x55eda5065e2b 0x55eda5195fe4 0x55eda5193ced 0x55eda5065e2b 0x55eda5195fe4 0x55eda5126afa 0x55eda5194915 0x55eda51939ee 0x55eda51936f3 0x55eda525d4c2 0x55eda525d83d 0x55eda525d6e6 0x55eda5235163\n","tcmalloc: large alloc 4294967296 bytes == 0x55eeabd04000 @  0x7fe6f1f821e7 0x7fe6ef18746e 0x7fe6ef1d7c7b 0x7fe6ef1d835f 0x7fe6ef27a103 0x55eda5125544 0x55eda5125240 0x55eda5199627 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda5126afa 0x55eda5194915 0x55eda51939ee 0x55eda5126bda 0x55eda5198d00 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda5193ced 0x55eda512748c 0x55eda5168159 0x55eda51650a4 0x55eda5125d49 0x55eda519994f\n","tcmalloc: large alloc 4294967296 bytes == 0x55efacfe0000 @  0x7fe6f1f821e7 0x7fe6ef18746e 0x7fe6ef1d7c7b 0x7fe6ef1d835f 0x7fe678b83235 0x7fe678506792 0x7fe678506d42 0x7fe6784bfaee 0x55eda5125437 0x55eda5125240 0x55eda51990f3 0x55eda5126afa 0x55eda5194c0d 0x55eda5193ced 0x55eda5065eb0 0x55eda5195fe4 0x55eda51939ee 0x55eda5126bda 0x55eda5194c0d 0x55eda5193ced 0x55eda5126bda 0x55eda5194c0d 0x55eda5126afa 0x55eda5194c0d 0x55eda51939ee 0x55eda5127271 0x55eda5127698 0x55eda5195fe4 0x55eda51939ee 0x55eda5126bda 0x55eda5194915\n","\n","Training options:\n","{\n","  \"G_args\": {\n","    \"func_name\": \"training.networks.G_main\",\n","    \"fmap_base\": 16384,\n","    \"fmap_max\": 512,\n","    \"mapping_layers\": 2,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"D_args\": {\n","    \"func_name\": \"training.networks.D_main\",\n","    \"mbstd_group_size\": 4,\n","    \"fmap_base\": 16384,\n","    \"fmap_max\": 512,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_opt_args\": {\n","    \"beta1\": 0.0,\n","    \"beta2\": 0.99,\n","    \"learning_rate\": 0.002\n","  },\n","  \"D_opt_args\": {\n","    \"beta1\": 0.0,\n","    \"beta2\": 0.99,\n","    \"learning_rate\": 0.002\n","  },\n","  \"loss_args\": {\n","    \"func_name\": \"training.loss.stylegan2\",\n","    \"r1_gamma\": 52.4288\n","  },\n","  \"augment_args\": {\n","    \"class_name\": \"training.augment.AdaptiveAugment\",\n","    \"tune_heuristic\": \"rt\",\n","    \"tune_target\": 0.6,\n","    \"apply_func\": \"training.augment.augment_pipeline\",\n","    \"apply_args\": {\n","      \"xflip\": 1,\n","      \"rotate90\": 1,\n","      \"xint\": 1,\n","      \"scale\": 1,\n","      \"rotate\": 1,\n","      \"aniso\": 1,\n","      \"xfrac\": 1,\n","      \"brightness\": 1,\n","      \"contrast\": 1,\n","      \"lumaflip\": 1,\n","      \"hue\": 1,\n","      \"saturation\": 1\n","    }\n","  },\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 2,\n","  \"network_snapshot_ticks\": 2,\n","  \"train_dataset_args\": {\n","    \"path\": \"/content/dataset/tfr_1024\",\n","    \"max_label_size\": 0,\n","    \"use_raw\": false,\n","    \"resolution\": 1024,\n","    \"mirror_augment\": true,\n","    \"mirror_augment_v\": false\n","  },\n","  \"metric_arg_list\": [],\n","  \"metric_dataset_args\": {\n","    \"path\": \"/content/dataset/tfr_1024\",\n","    \"max_label_size\": 0,\n","    \"use_raw\": false,\n","    \"resolution\": 1024,\n","    \"mirror_augment\": true,\n","    \"mirror_augment_v\": false\n","  },\n","  \"total_kimg\": 25000,\n","  \"minibatch_size\": 4,\n","  \"minibatch_gpu\": 4,\n","  \"G_smoothing_kimg\": 1.25,\n","  \"G_smoothing_rampup\": 0.05,\n","  \"run_dir\": \"/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00005-tfr_1024-mirror-auto1-bgc-noresume\"\n","}\n","\n","Output directory:  /content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00005-tfr_1024-mirror-auto1-bgc-noresume\n","Training data:     /content/dataset/tfr_1024\n","Training length:   25000 kimg\n","Resolution:        1024\n","Number of GPUs:    1\n","\n","Creating output directory...\n","Loading training set...\n","tcmalloc: large alloc 4294967296 bytes == 0x55edaba02000 @  0x7fe6f1f84001 0x7fe6ef18754f 0x7fe6ef1d7b58 0x7fe6ef1dbb17 0x7fe6ef27a203 0x55eda5125544 0x55eda5125240 0x55eda5199627 0x55eda5193ced 0x55eda512748c 0x55eda5168159 0x55eda51650a4 0x55eda5125d49 0x55eda519994f 0x55eda51939ee 0x55eda5065e2b 0x55eda5195fe4 0x55eda51939ee 0x55eda5065e2b 0x55eda5195fe4 0x55eda5193ced 0x55eda5065e2b 0x55eda5195fe4 0x55eda5126afa 0x55eda5194915 0x55eda51939ee 0x55eda51936f3 0x55eda525d4c2 0x55eda525d83d 0x55eda525d6e6 0x55eda5235163\n","tcmalloc: large alloc 4294967296 bytes == 0x55f0acfe0000 @  0x7fe6f1f821e7 0x7fe6ef18746e 0x7fe6ef1d7c7b 0x7fe6ef1d835f 0x7fe6ef27a103 0x55eda5125544 0x55eda5125240 0x55eda5199627 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda5126afa 0x55eda5194915 0x55eda51939ee 0x55eda5126bda 0x55eda5198d00 0x55eda51939ee 0x55eda5126bda 0x55eda5195737 0x55eda5193ced 0x55eda512748c 0x55eda5168159 0x55eda51650a4 0x55eda5125d49 0x55eda519994f\n","tcmalloc: large alloc 4294967296 bytes == 0x55f0acfe0000 @  0x7fe6f1f821e7 0x7fe6ef18746e 0x7fe6ef1d7c7b 0x7fe6ef1d835f 0x7fe678b83235 0x7fe678506792 0x7fe678506d42 0x7fe6784bfaee 0x55eda5125437 0x55eda5125240 0x55eda51990f3 0x55eda5126afa 0x55eda5194c0d 0x55eda5193ced 0x55eda5065eb0 0x55eda5195fe4 0x55eda51939ee 0x55eda5126bda 0x55eda5194c0d 0x55eda5193ced 0x55eda5126bda 0x55eda5194c0d 0x55eda5126afa 0x55eda5194c0d 0x55eda51939ee 0x55eda5127271 0x55eda5127698 0x55eda5195fe4 0x55eda51939ee 0x55eda5126bda 0x55eda5194915\n","Image shape: [3, 1024, 1024]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n","\n","G                               Params    OutputShape          WeightShape     \n","---                             ---       ---                  ---             \n","latents_in                      -         (?, 512)             -               \n","labels_in                       -         (?, 0)               -               \n","epochs                          1         ()                   ()              \n","epochs_1                        1         ()                   ()              \n","G_mapping/Normalize             -         (?, 512)             -               \n","G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n","G_mapping/Broadcast             -         (?, 18, 512)         -               \n","dlatent_avg                     -         (512,)               -               \n","Truncation/Lerp                 -         (?, 18, 512)         -               \n","G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n","G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n","G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n","G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n","G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n","G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n","G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n","G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n","G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n","G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n","G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n","G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n","G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n","G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n","G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n","G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n","G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n","G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n","G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n","G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n","G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n","---                             ---       ---                  ---             \n","Total                           28794126                                       \n","\n","\n","D                     Params    OutputShape          WeightShape     \n","---                   ---       ---                  ---             \n","images_in             -         (?, 3, 1024, 1024)   -               \n","labels_in             -         (?, 0)               -               \n","1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n","1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n","1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n","1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n","512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n","512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n","512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n","256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n","256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n","256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n","128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n","128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n","128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n","64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n","64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n","64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n","32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n","32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n","32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n","16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n","16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n","16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n","8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n","8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n","8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n","4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n","4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n","4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n","Output                513       (?, 1)               (512, 1)        \n","---                   ---       ---                  ---             \n","Total                 29012513                                       \n","\n","Exporting sample images...\n","2021-12-28 19:16:53.799603: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 88080384 exceeds 10% of system memory.\n","Replicating networks across 1 GPUs...\n","Initializing augmentations...\n","Setting up optimizers...\n","Constructing training graph...\n","Finalizing training ops...\n","2021-12-28 19:17:38.889593: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 50331648 exceeds 10% of system memory.\n","2021-12-28 19:17:38.900057: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 50331648 exceeds 10% of system memory.\n","2021-12-28 19:17:38.917462: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 50331648 exceeds 10% of system memory.\n","2021-12-28 19:17:38.925054: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 50331648 exceeds 10% of system memory.\n","Initializing metrics...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 2m 28s       sec/tick 59.9    sec/kimg 3744.57 maintenance 88.6   gpumem 10.3  augment 0.000\n","tick 1     kimg 4.0      time 34m 47s      sec/tick 1923.0  sec/kimg 480.76  maintenance 15.3   gpumem 10.3  augment 0.006\n","tick 2     kimg 8.0      time 1h 06m 51s   sec/tick 1924.6  sec/kimg 481.15  maintenance 0.0    gpumem 10.3  augment 0.013\n","tick 3     kimg 12.0     time 1h 39m 01s   sec/tick 1926.0  sec/kimg 481.49  maintenance 3.4    gpumem 10.3  augment 0.020\n","tick 4     kimg 16.0     time 2h 11m 09s   sec/tick 1928.6  sec/kimg 482.16  maintenance 0.0    gpumem 10.3  augment 0.027\n","tick 5     kimg 20.0     time 2h 43m 22s   sec/tick 1929.5  sec/kimg 482.38  maintenance 3.4    gpumem 10.3  augment 0.033\n","tick 6     kimg 24.0     time 3h 15m 35s   sec/tick 1932.6  sec/kimg 483.14  maintenance 0.0    gpumem 10.3  augment 0.039\n","tick 7     kimg 28.0     time 3h 47m 52s   sec/tick 1934.0  sec/kimg 483.51  maintenance 3.4    gpumem 10.3  augment 0.045\n","tick 8     kimg 32.0     time 4h 20m 09s   sec/tick 1936.3  sec/kimg 484.07  maintenance 0.0    gpumem 10.3  augment 0.051\n","tick 9     kimg 36.0     time 4h 52m 30s   sec/tick 1937.7  sec/kimg 484.43  maintenance 3.5    gpumem 10.3  augment 0.057\n","tick 10    kimg 40.0     time 5h 24m 49s   sec/tick 1939.6  sec/kimg 484.91  maintenance 0.0    gpumem 10.3  augment 0.062\n","tick 11    kimg 44.0     time 5h 57m 13s   sec/tick 1940.4  sec/kimg 485.10  maintenance 3.4    gpumem 10.3  augment 0.068\n","tick 12    kimg 48.0     time 6h 29m 36s   sec/tick 1942.8  sec/kimg 485.69  maintenance 0.0    gpumem 10.3  augment 0.074\n","tick 13    kimg 52.0     time 7h 02m 03s   sec/tick 1943.3  sec/kimg 485.82  maintenance 3.4    gpumem 10.3  augment 0.081\n","tick 14    kimg 56.0     time 7h 34m 28s   sec/tick 1945.4  sec/kimg 486.35  maintenance 0.0    gpumem 10.3  augment 0.087\n","tick 15    kimg 60.0     time 8h 06m 58s   sec/tick 1946.1  sec/kimg 486.53  maintenance 3.4    gpumem 10.3  augment 0.093\n","tick 16    kimg 64.0     time 8h 39m 26s   sec/tick 1948.4  sec/kimg 487.11  maintenance 0.0    gpumem 10.3  augment 0.098\n","tick 17    kimg 68.0     time 9h 11m 58s   sec/tick 1948.4  sec/kimg 487.11  maintenance 3.5    gpumem 10.3  augment 0.101\n","tick 18    kimg 72.0     time 9h 44m 28s   sec/tick 1949.5  sec/kimg 487.39  maintenance 0.0    gpumem 10.3  augment 0.105\n","tick 19    kimg 76.0     time 10h 17m 01s  sec/tick 1949.9  sec/kimg 487.47  maintenance 3.5    gpumem 10.3  augment 0.111\n","tick 20    kimg 80.0     time 10h 49m 32s  sec/tick 1951.5  sec/kimg 487.87  maintenance 0.0    gpumem 10.3  augment 0.116\n","tick 21    kimg 84.0     time 11h 22m 09s  sec/tick 1952.9  sec/kimg 488.22  maintenance 3.5    gpumem 10.3  augment 0.120\n","tick 22    kimg 88.0     time 11h 54m 42s  sec/tick 1953.3  sec/kimg 488.32  maintenance 0.0    gpumem 10.3  augment 0.122\n","tick 23    kimg 92.0     time 12h 27m 19s  sec/tick 1953.8  sec/kimg 488.46  maintenance 3.4    gpumem 10.3  augment 0.124\n","tick 24    kimg 96.0     time 12h 59m 54s  sec/tick 1954.8  sec/kimg 488.69  maintenance 0.0    gpumem 10.3  augment 0.128\n","tick 25    kimg 100.0    time 13h 32m 32s  sec/tick 1954.1  sec/kimg 488.54  maintenance 3.6    gpumem 10.3  augment 0.132\n","tick 26    kimg 104.0    time 14h 05m 08s  sec/tick 1956.1  sec/kimg 489.02  maintenance 0.0    gpumem 10.3  augment 0.134\n","tick 27    kimg 108.0    time 14h 37m 48s  sec/tick 1957.3  sec/kimg 489.32  maintenance 3.3    gpumem 10.3  augment 0.138\n"]}],"source":["training_path = project_path / 'training' / dataset_name\n","if not training_path.is_dir():\n","    %mkdir \"{training_path}\"\n","\n","#how often should the model generate samples and a .pkl file\n","snapshot_count = 2\n","#should the images be mirrored left to right?\n","mirrored = True\n","#should the images be mirrored top to bottom?\n","mirroredY = False\n","#metrics?\n","metric_list = None\n","#augments\n","augs = 'bgc'\n","\n","resume_from = 'noresume'\n","\n","!python \"{stylegan2_repo_path / 'train.py'}\" --outdir=\"{training_path}\" \\\n","    --data=\"{local_dataset_path}\" --resume=\"{resume_from}\" \\\n","    --snap={snapshot_count} --augpipe={augs} \\\n","    --mirror={mirrored} --mirrory={mirroredY} --cfg={'auto'} \\\n","    --metrics={metric_list} #--dry-run"]},{"cell_type":"markdown","metadata":{"id":"f0A9ZNtferpk"},"source":["## Generate images from pre-trained model\n","\n","You can finally generate images using a pre-trained network once everything is set-up. You can naturally use [your own model once it is trained](#scrollTo=Ti11YiPAiQpb&uniqifier=1) or use the ones NVLab published on [their website](https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/).\n","\n","<p align=\"center\">\n","    <img\n","    alt=\"Night Sky Latent Walk\"\n","    width=\"450\" height=\"300\"\n","    src=\"https://github.com/ArthurFDLR/GANightSky/blob/main/.github/Random_Generation.png?raw=true\">\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7021,"status":"ok","timestamp":1640575717017,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":300},"id":"xnlrb9QzgaGp","outputId":"2cb3a97e-e41f-48f6-c716-d81a83db2b10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opensimplex in /usr/local/lib/python3.7/dist-packages (0.3)\n","usage: generate.py generate-images [-h] --network NETWORK_PKL --seeds SEEDS\n","                                   [--trunc TRUNCATION_PSI]\n","                                   [--class CLASS_IDX] [--create-grid]\n","                                   [--outdir DIR] [--save_vector] [--fixnoise]\n","                                   [--jpg_quality JPG_QUALITY]\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  --network NETWORK_PKL\n","                        Network pickle filename\n","  --seeds SEEDS         List of random seeds\n","  --trunc TRUNCATION_PSI\n","                        Truncation psi (default: 0.5)\n","  --class CLASS_IDX     Class label (default: unconditional)\n","  --create-grid         Add flag to save the generated images in a grid\n","  --outdir DIR          Root directory for run results (default: out)\n","  --save_vector         also save vector in .npy format\n","  --fixnoise            generate images using fixed noise (more accurate for\n","                        interpolations)\n","  --jpg_quality JPG_QUALITY\n","                        Quality compression for JPG exports (1 to 95), keep\n","                        default value to export as PNG\n"]}],"source":["%pip install opensimplex\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images --help "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19907,"status":"ok","timestamp":1640578645560,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":300},"id":"qQqYjeRsfYD2","outputId":"c48d5f07-5c27-4b1f-947f-ca8e85e8512a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading networks from \"/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00000-tfr-mirror-auto1-bgc-noresume-256_de_curto_and_de_zarza/network-snapshot-000798.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n","Generating image for seed 5269 (0/100) ...\n","Generating image for seed 5270 (1/100) ...\n","Generating image for seed 5271 (2/100) ...\n","Generating image for seed 5272 (3/100) ...\n","Generating image for seed 5273 (4/100) ...\n","Generating image for seed 5274 (5/100) ...\n","Generating image for seed 5275 (6/100) ...\n","Generating image for seed 5276 (7/100) ...\n","Generating image for seed 5277 (8/100) ...\n","Generating image for seed 5278 (9/100) ...\n","Generating image for seed 5279 (10/100) ...\n","Generating image for seed 5280 (11/100) ...\n","Generating image for seed 5281 (12/100) ...\n","Generating image for seed 5282 (13/100) ...\n","Generating image for seed 5283 (14/100) ...\n","Generating image for seed 5284 (15/100) ...\n","Generating image for seed 5285 (16/100) ...\n","Generating image for seed 5286 (17/100) ...\n","Generating image for seed 5287 (18/100) ...\n","Generating image for seed 5288 (19/100) ...\n","Generating image for seed 5289 (20/100) ...\n","Generating image for seed 5290 (21/100) ...\n","Generating image for seed 5291 (22/100) ...\n","Generating image for seed 5292 (23/100) ...\n","Generating image for seed 5293 (24/100) ...\n","Generating image for seed 5294 (25/100) ...\n","Generating image for seed 5295 (26/100) ...\n","Generating image for seed 5296 (27/100) ...\n","Generating image for seed 5297 (28/100) ...\n","Generating image for seed 5298 (29/100) ...\n","Generating image for seed 5299 (30/100) ...\n","Generating image for seed 5300 (31/100) ...\n","Generating image for seed 5301 (32/100) ...\n","Generating image for seed 5302 (33/100) ...\n","Generating image for seed 5303 (34/100) ...\n","Generating image for seed 5304 (35/100) ...\n","Generating image for seed 5305 (36/100) ...\n","Generating image for seed 5306 (37/100) ...\n","Generating image for seed 5307 (38/100) ...\n","Generating image for seed 5308 (39/100) ...\n","Generating image for seed 5309 (40/100) ...\n","Generating image for seed 5310 (41/100) ...\n","Generating image for seed 5311 (42/100) ...\n","Generating image for seed 5312 (43/100) ...\n","Generating image for seed 5313 (44/100) ...\n","Generating image for seed 5314 (45/100) ...\n","Generating image for seed 5315 (46/100) ...\n","Generating image for seed 5316 (47/100) ...\n","Generating image for seed 5317 (48/100) ...\n","Generating image for seed 5318 (49/100) ...\n","Generating image for seed 5319 (50/100) ...\n","Generating image for seed 5320 (51/100) ...\n","Generating image for seed 5321 (52/100) ...\n","Generating image for seed 5322 (53/100) ...\n","Generating image for seed 5323 (54/100) ...\n","Generating image for seed 5324 (55/100) ...\n","Generating image for seed 5325 (56/100) ...\n","Generating image for seed 5326 (57/100) ...\n","Generating image for seed 5327 (58/100) ...\n","Generating image for seed 5328 (59/100) ...\n","Generating image for seed 5329 (60/100) ...\n","Generating image for seed 5330 (61/100) ...\n","Generating image for seed 5331 (62/100) ...\n","Generating image for seed 5332 (63/100) ...\n","Generating image for seed 5333 (64/100) ...\n","Generating image for seed 5334 (65/100) ...\n","Generating image for seed 5335 (66/100) ...\n","Generating image for seed 5336 (67/100) ...\n","Generating image for seed 5337 (68/100) ...\n","Generating image for seed 5338 (69/100) ...\n","Generating image for seed 5339 (70/100) ...\n","Generating image for seed 5340 (71/100) ...\n","Generating image for seed 5341 (72/100) ...\n","Generating image for seed 5342 (73/100) ...\n","Generating image for seed 5343 (74/100) ...\n","Generating image for seed 5344 (75/100) ...\n","Generating image for seed 5345 (76/100) ...\n","Generating image for seed 5346 (77/100) ...\n","Generating image for seed 5347 (78/100) ...\n","Generating image for seed 5348 (79/100) ...\n","Generating image for seed 5349 (80/100) ...\n","Generating image for seed 5350 (81/100) ...\n","Generating image for seed 5351 (82/100) ...\n","Generating image for seed 5352 (83/100) ...\n","Generating image for seed 5353 (84/100) ...\n","Generating image for seed 5354 (85/100) ...\n","Generating image for seed 5355 (86/100) ...\n","Generating image for seed 5356 (87/100) ...\n","Generating image for seed 5357 (88/100) ...\n","Generating image for seed 5358 (89/100) ...\n","Generating image for seed 5359 (90/100) ...\n","Generating image for seed 5360 (91/100) ...\n","Generating image for seed 5361 (92/100) ...\n","Generating image for seed 5362 (93/100) ...\n","Generating image for seed 5363 (94/100) ...\n","Generating image for seed 5364 (95/100) ...\n","Generating image for seed 5365 (96/100) ...\n","Generating image for seed 5366 (97/100) ...\n","Generating image for seed 5367 (98/100) ...\n","Generating image for seed 5368 (99/100) ...\n","Generating image grid...\n"]}],"source":["from numpy import random\n","seed_init = random.randint(10000)\n","nbr_images = 100\n","\n","generation_from = '/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00000-tfr-mirror-auto1-bgc-noresume-256_de_curto_and_de_zarza/network-snapshot-000798.pkl'\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images \\\n","    --outdir=\"{project_path / 'out' / 'dr_cyz_256_100'}\" --trunc=0.7 \\\n","    --seeds={seed_init}-{seed_init+nbr_images-1} --create-grid \\\n","    --network={generation_from}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jAj6lOM82Fq9","outputId":"1c371c61-d83f-4426-e11f-c132a5ad5683"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading network from \"/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00000-tfr-mirror-auto1-bgc-noresume-256_de_curto_and_de_zarza/network-snapshot-000798.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n","\n","Gs                            Params    OutputShape         WeightShape     \n","---                           ---       ---                 ---             \n","latents_in                    -         (?, 512)            -               \n","labels_in                     -         (?, 0)              -               \n","G_mapping/Normalize           -         (?, 512)            -               \n","G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n","G_mapping/Broadcast           -         (?, 14, 512)        -               \n","dlatent_avg                   -         (512,)              -               \n","Truncation/Lerp               -         (?, 14, 512)        -               \n","G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n","G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n","G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n","G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n","G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n","G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n","G_synthesis/64x64/Conv0_up    1442561   (?, 256, 64, 64)    (3, 3, 512, 256)\n","G_synthesis/64x64/Conv1       721409    (?, 256, 64, 64)    (3, 3, 256, 256)\n","G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n","G_synthesis/64x64/ToRGB       132099    (?, 3, 64, 64)      (1, 1, 256, 3)  \n","G_synthesis/128x128/Conv0_up  426369    (?, 128, 128, 128)  (3, 3, 256, 128)\n","G_synthesis/128x128/Conv1     213249    (?, 128, 128, 128)  (3, 3, 128, 128)\n","G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n","G_synthesis/128x128/ToRGB     66051     (?, 3, 128, 128)    (1, 1, 128, 3)  \n","G_synthesis/256x256/Conv0_up  139457    (?, 64, 256, 256)   (3, 3, 128, 64) \n","G_synthesis/256x256/Conv1     69761     (?, 64, 256, 256)   (3, 3, 64, 64)  \n","G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n","G_synthesis/256x256/ToRGB     33027     (?, 3, 256, 256)    (1, 1, 64, 3)   \n","---                           ---       ---                 ---             \n","Total                         23191522                                      \n","\n","Looking up training options from \"/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00000-tfr-mirror-auto1-bgc-noresume-256_de_curto_and_de_zarza/training_options.json\"...\n","\n","Dataset options:\n","{\n","  \"path\": \"/content/dataset/tfr_256\",\n","  \"max_label_size\": 0,\n","  \"use_raw\": false,\n","  \"resolution\": 256,\n","  \"mirror_augment\": true,\n","  \"mirror_augment_v\": false\n","}\n","\n","Evaluating fid50k_full...\n","Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metrics/inception_v3_features.pkl ... done\n","Calculating real image statistics for fid50k_full...\n","tcmalloc: large alloc 4294967296 bytes == 0x557e2a2f6000 @  0x7fef41074001 0x7fef3e2b754f 0x7fef3e307b58 0x7fef3e30bb17 0x7fef3e3aa203 0x557de33fa544 0x557de33fa240 0x557de346e627 0x557de3468ced 0x557de33fc48c 0x557de343d159 0x557de343a0a4 0x557de33fad49 0x557de346e94f 0x557de34689ee 0x557de333ae2b 0x557de346afe4 0x557de33fbafa 0x557de3469c0d 0x557de34eccf8 0x557de3469daf 0x557de34689ee 0x557de33fbbda 0x557de346a737 0x557de34689ee 0x557de33fbbda 0x557de346a737 0x557de34689ee 0x557de333ae2b 0x557de346afe4 0x557de33fbafa\n","tcmalloc: large alloc 4294967296 bytes == 0x557f2a2f6000 @  0x7fef410721e7 0x7fef3e2b746e 0x7fef3e307c7b 0x7fef3e30835f 0x7fef3e3aa103 0x557de33fa544 0x557de33fa240 0x557de346e627 0x557de34689ee 0x557de33fbbda 0x557de346a737 0x557de34689ee 0x557de33fbbda 0x557de346a737 0x557de34689ee 0x557de33fbbda 0x557de346a737 0x557de33fbafa 0x557de3469915 0x557de34689ee 0x557de33fbbda 0x557de346dd00 0x557de34689ee 0x557de33fbbda 0x557de346a737 0x557de3468ced 0x557de33fc48c 0x557de343d159 0x557de343a0a4 0x557de33fad49 0x557de346e94f\n","tcmalloc: large alloc 4294967296 bytes == 0x557f2a2f6000 @  0x7fef410721e7 0x7fef3e2b746e 0x7fef3e307c7b 0x7fef3e30835f 0x7feec7141235 0x7feec6ac4792 0x7feec6ac4d42 0x7feec6a7daee 0x557de33fa437 0x557de33fa240 0x557de346e0f3 0x557de33fbafa 0x557de3469c0d 0x557de3468ced 0x557de333aeb0 0x557de346afe4 0x557de34689ee 0x557de33fbbda 0x557de3469c0d 0x557de3468ced 0x557de33fbbda 0x557de3469c0d 0x557de33fbafa 0x557de3469c0d 0x557de34689ee 0x557de33fc271 0x557de33fc698 0x557de346afe4 0x557de34689ee 0x557de33fbbda 0x557de3469915\n"]}],"source":["#Run this cell to compute FID metric data, if desired.\n","\n","generation_from = '/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00000-tfr-mirror-auto1-bgc-noresume-256_de_curto_and_de_zarza/network-snapshot-000798.pkl'\n","!python \"{stylegan2_repo_path / 'calc_metrics.py'}\" \\\n","    --metrics=fid50k_full --metricdata=\"{local_dataset_path}\" --mirror=1 --network={generation_from}   "]},{"cell_type":"markdown","metadata":{"id":"5yG1UyHXXqsO"},"source":["## Latent space exploration"]},{"cell_type":"markdown","metadata":{"id":"kYLhEFGMtJIw"},"source":["It is also possible to explore the latent space associated with our model and [generate videos like this one](https://youtu.be/dcb4Ckpkx2o).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9035,"status":"ok","timestamp":1640578792245,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":300},"id":"veceGR6QYA93","outputId":"4d37917a-7519-4e2f-ffad-e673b444d729"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opensimplex in /usr/local/lib/python3.7/dist-packages (0.3)\n","usage: generate.py generate-latent-walk [-h] --network NETWORK_PKL\n","                                        [--trunc TRUNCATION_PSI]\n","                                        [--walk-type WALK_TYPE]\n","                                        [--frames FRAMES] [--fps FRAMERATE]\n","                                        [--seeds SEEDS] [--npys NPYS]\n","                                        [--save_vector] [--diameter DIAMETER]\n","                                        [--start_seed START_SEED]\n","                                        [--outdir DIR]\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  --network NETWORK_PKL\n","                        Network pickle filename\n","  --trunc TRUNCATION_PSI\n","                        Truncation psi (default: 0.5)\n","  --walk-type WALK_TYPE\n","                        Type of walk (default: line)\n","  --frames FRAMES       Frame count (default: 240\n","  --fps FRAMERATE       Starting value\n","  --seeds SEEDS         List of random seeds\n","  --npys NPYS           List of .npy files\n","  --save_vector         also save vector in .npy format\n","  --diameter DIAMETER   diameter of noise loop\n","  --start_seed START_SEED\n","                        random seed to start noise loop from\n","  --outdir DIR          Root directory for run results (default: out)\n"]}],"source":["%pip install opensimplex\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --help "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24879,"status":"ok","timestamp":1640579211133,"user":{"displayName":"J. de Curtò i DíAz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgQiCjsgP6GeIR4b7BFfGKinGjOnk7yPbXdSPElxQ=s64","userId":"16993687310987141516"},"user_tz":300},"id":"UjsN05ksZYZ7","outputId":"b1782013-f787-4a17-80ca-20b1cdeb54a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["1063,5112,8352,7866,2074,7117,2999,2892,2821,7171\n","Base seeds: [1063, 5112, 8352, 7866, 2074, 7117, 2999, 2892, 2821, 7171]\n","Loading networks from \"/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00000-tfr-mirror-auto1-bgc-noresume-256_de_curto_and_de_zarza/network-snapshot-000798.pkl\"...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n","slerp\n","Generating image for step 0/207 ...\n","Generating image for step 1/207 ...\n","Generating image for step 2/207 ...\n","Generating image for step 3/207 ...\n","Generating image for step 4/207 ...\n","Generating image for step 5/207 ...\n","Generating image for step 6/207 ...\n","Generating image for step 7/207 ...\n","Generating image for step 8/207 ...\n","Generating image for step 9/207 ...\n","Generating image for step 10/207 ...\n","Generating image for step 11/207 ...\n","Generating image for step 12/207 ...\n","Generating image for step 13/207 ...\n","Generating image for step 14/207 ...\n","Generating image for step 15/207 ...\n","Generating image for step 16/207 ...\n","Generating image for step 17/207 ...\n","Generating image for step 18/207 ...\n","Generating image for step 19/207 ...\n","Generating image for step 20/207 ...\n","Generating image for step 21/207 ...\n","Generating image for step 22/207 ...\n","Generating image for step 23/207 ...\n","Generating image for step 24/207 ...\n","Generating image for step 25/207 ...\n","Generating image for step 26/207 ...\n","Generating image for step 27/207 ...\n","Generating image for step 28/207 ...\n","Generating image for step 29/207 ...\n","Generating image for step 30/207 ...\n","Generating image for step 31/207 ...\n","Generating image for step 32/207 ...\n","Generating image for step 33/207 ...\n","Generating image for step 34/207 ...\n","Generating image for step 35/207 ...\n","Generating image for step 36/207 ...\n","Generating image for step 37/207 ...\n","Generating image for step 38/207 ...\n","Generating image for step 39/207 ...\n","Generating image for step 40/207 ...\n","Generating image for step 41/207 ...\n","Generating image for step 42/207 ...\n","Generating image for step 43/207 ...\n","Generating image for step 44/207 ...\n","Generating image for step 45/207 ...\n","Generating image for step 46/207 ...\n","Generating image for step 47/207 ...\n","Generating image for step 48/207 ...\n","Generating image for step 49/207 ...\n","Generating image for step 50/207 ...\n","Generating image for step 51/207 ...\n","Generating image for step 52/207 ...\n","Generating image for step 53/207 ...\n","Generating image for step 54/207 ...\n","Generating image for step 55/207 ...\n","Generating image for step 56/207 ...\n","Generating image for step 57/207 ...\n","Generating image for step 58/207 ...\n","Generating image for step 59/207 ...\n","Generating image for step 60/207 ...\n","Generating image for step 61/207 ...\n","Generating image for step 62/207 ...\n","Generating image for step 63/207 ...\n","Generating image for step 64/207 ...\n","Generating image for step 65/207 ...\n","Generating image for step 66/207 ...\n","Generating image for step 67/207 ...\n","Generating image for step 68/207 ...\n","Generating image for step 69/207 ...\n","Generating image for step 70/207 ...\n","Generating image for step 71/207 ...\n","Generating image for step 72/207 ...\n","Generating image for step 73/207 ...\n","Generating image for step 74/207 ...\n","Generating image for step 75/207 ...\n","Generating image for step 76/207 ...\n","Generating image for step 77/207 ...\n","Generating image for step 78/207 ...\n","Generating image for step 79/207 ...\n","Generating image for step 80/207 ...\n","Generating image for step 81/207 ...\n","Generating image for step 82/207 ...\n","Generating image for step 83/207 ...\n","Generating image for step 84/207 ...\n","Generating image for step 85/207 ...\n","Generating image for step 86/207 ...\n","Generating image for step 87/207 ...\n","Generating image for step 88/207 ...\n","Generating image for step 89/207 ...\n","Generating image for step 90/207 ...\n","Generating image for step 91/207 ...\n","Generating image for step 92/207 ...\n","Generating image for step 93/207 ...\n","Generating image for step 94/207 ...\n","Generating image for step 95/207 ...\n","Generating image for step 96/207 ...\n","Generating image for step 97/207 ...\n","Generating image for step 98/207 ...\n","Generating image for step 99/207 ...\n","Generating image for step 100/207 ...\n","Generating image for step 101/207 ...\n","Generating image for step 102/207 ...\n","Generating image for step 103/207 ...\n","Generating image for step 104/207 ...\n","Generating image for step 105/207 ...\n","Generating image for step 106/207 ...\n","Generating image for step 107/207 ...\n","Generating image for step 108/207 ...\n","Generating image for step 109/207 ...\n","Generating image for step 110/207 ...\n","Generating image for step 111/207 ...\n","Generating image for step 112/207 ...\n","Generating image for step 113/207 ...\n","Generating image for step 114/207 ...\n","Generating image for step 115/207 ...\n","Generating image for step 116/207 ...\n","Generating image for step 117/207 ...\n","Generating image for step 118/207 ...\n","Generating image for step 119/207 ...\n","Generating image for step 120/207 ...\n","Generating image for step 121/207 ...\n","Generating image for step 122/207 ...\n","Generating image for step 123/207 ...\n","Generating image for step 124/207 ...\n","Generating image for step 125/207 ...\n","Generating image for step 126/207 ...\n","Generating image for step 127/207 ...\n","Generating image for step 128/207 ...\n","Generating image for step 129/207 ...\n","Generating image for step 130/207 ...\n","Generating image for step 131/207 ...\n","Generating image for step 132/207 ...\n","Generating image for step 133/207 ...\n","Generating image for step 134/207 ...\n","Generating image for step 135/207 ...\n","Generating image for step 136/207 ...\n","Generating image for step 137/207 ...\n","Generating image for step 138/207 ...\n","Generating image for step 139/207 ...\n","Generating image for step 140/207 ...\n","Generating image for step 141/207 ...\n","Generating image for step 142/207 ...\n","Generating image for step 143/207 ...\n","Generating image for step 144/207 ...\n","Generating image for step 145/207 ...\n","Generating image for step 146/207 ...\n","Generating image for step 147/207 ...\n","Generating image for step 148/207 ...\n","Generating image for step 149/207 ...\n","Generating image for step 150/207 ...\n","Generating image for step 151/207 ...\n","Generating image for step 152/207 ...\n","Generating image for step 153/207 ...\n","Generating image for step 154/207 ...\n","Generating image for step 155/207 ...\n","Generating image for step 156/207 ...\n","Generating image for step 157/207 ...\n","Generating image for step 158/207 ...\n","Generating image for step 159/207 ...\n","Generating image for step 160/207 ...\n","Generating image for step 161/207 ...\n","Generating image for step 162/207 ...\n","Generating image for step 163/207 ...\n","Generating image for step 164/207 ...\n","Generating image for step 165/207 ...\n","Generating image for step 166/207 ...\n","Generating image for step 167/207 ...\n","Generating image for step 168/207 ...\n","Generating image for step 169/207 ...\n","Generating image for step 170/207 ...\n","Generating image for step 171/207 ...\n","Generating image for step 172/207 ...\n","Generating image for step 173/207 ...\n","Generating image for step 174/207 ...\n","Generating image for step 175/207 ...\n","Generating image for step 176/207 ...\n","Generating image for step 177/207 ...\n","Generating image for step 178/207 ...\n","Generating image for step 179/207 ...\n","Generating image for step 180/207 ...\n","Generating image for step 181/207 ...\n","Generating image for step 182/207 ...\n","Generating image for step 183/207 ...\n","Generating image for step 184/207 ...\n","Generating image for step 185/207 ...\n","Generating image for step 186/207 ...\n","Generating image for step 187/207 ...\n","Generating image for step 188/207 ...\n","Generating image for step 189/207 ...\n","Generating image for step 190/207 ...\n","Generating image for step 191/207 ...\n","Generating image for step 192/207 ...\n","Generating image for step 193/207 ...\n","Generating image for step 194/207 ...\n","Generating image for step 195/207 ...\n","Generating image for step 196/207 ...\n","Generating image for step 197/207 ...\n","Generating image for step 198/207 ...\n","Generating image for step 199/207 ...\n","Generating image for step 200/207 ...\n","Generating image for step 201/207 ...\n","Generating image for step 202/207 ...\n","Generating image for step 203/207 ...\n","Generating image for step 204/207 ...\n","Generating image for step 205/207 ...\n","Generating image for step 206/207 ...\n","ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, image2, from '/content/drive/MyDrive/StyleGAN2-ADA/out/latent_walk_sphere_cyz_256/frames/frame%05d.png':\n","  Duration: 00:00:08.28, start: 0.000000, bitrate: N/A\n","    Stream #0:0: Video: png, rgb24(pc), 256x256, 25 fps, 25 tbr, 25 tbn, 25 tbc\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mprofile High, level 1.3\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to '/content/drive/MyDrive/StyleGAN2-ADA/out/latent_walk_sphere_cyz_256/walk-z-sphere-seed0-24fps.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 256x256, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame=  207 fps=0.0 q=-1.0 Lsize=     263kB time=00:00:08.50 bitrate= 253.1kbits/s speed=9.05x    \n","video:260kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.854566%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mframe I:1     Avg QP:23.18  size:  8528\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mframe P:161   Avg QP:22.98  size:  1572\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mframe B:45    Avg QP:30.04  size:    99\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mconsecutive B-frames: 65.7% 10.6% 15.9%  7.7%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mmb I  I16..4:  9.8% 74.2% 16.0%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mmb P  I16..4:  0.3%  0.6%  0.1%  P16..4: 50.6% 10.1% 13.5%  0.0%  0.0%    skip:24.7%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 17.4%  0.4%  0.1%  direct: 0.9%  skip:81.2%  L0:24.0% L1:69.6% BI: 6.4%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0m8x8 transform intra:65.6% inter:52.9%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mcoded y,uvDC,uvAC intra: 74.6% 55.5% 9.4% inter: 33.2% 31.2% 1.3%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mi16 v,h,dc,p: 30% 57%  1% 12%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  7% 23% 32%  5%  3%  3%  9%  4% 14%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 31% 16% 10%  5%  3%  8%  4% 11%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mi8c dc,h,v,p: 47% 30% 16%  7%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mWeighted P-Frames: Y:70.2% UV:11.8%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mref P L0: 65.1% 23.8% 10.4%  0.4%  0.2%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mref B L0: 92.8%  7.0%  0.2%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mref B L1: 99.8%  0.2%\n","\u001b[1;36m[libx264 @ 0x55d3cd8fde00] \u001b[0mkb/s:246.72\n"]}],"source":["from numpy import random\n","walk_types = ['line', 'sphere', 'noiseloop', 'circularloop']\n","latent_walk_path = project_path / 'out' / 'latent_walk_sphere_cyz_256'\n","if not latent_walk_path.is_dir():\n","    %mkdir \"{latent_walk_path}\"\n","\n","explored_network = '/content/drive/MyDrive/StyleGAN2-ADA/training/dr_cyz/00000-tfr-mirror-auto1-bgc-noresume-256_de_curto_and_de_zarza/network-snapshot-000798.pkl'\n","\n","seeds = [random.randint(10000) for i in range(10)]\n","print(','.join(map(str, seeds)))\n","print(\"Base seeds:\", seeds)\n","!python \"{stylegan2_repo_path / 'generate.py'}\" generate-latent-walk --network=\"{explored_network}\" \\\n","    --outdir=\"{latent_walk_path}\" --trunc=0.7 --walk-type=\"{walk_types[1]}\" \\\n","    --seeds={','.join(map(str, seeds))} --frames {len(seeds)*20}"]},{"cell_type":"markdown","metadata":{"id":"H9878RlntrDp"},"source":["## While you wait ...\n","\n","... learn more about Generative Adversarial Networks and StyleGAN2-ADA:\n","\n","*   [This Night Sky Does Not Exist](https://arthurfindelair.com/thisnightskydoesnotexist/): Generation of images from a model created using this Notebook on Google Colab Pro.\n","*   [This **X** Does Not Exist](https://thisxdoesnotexist.com/): Collection of sites showing the power of GANs.\n","*   [Karras, Tero, et al. _Analyzing and Improving the Image Quality of StyleGAN._ CVPR 2020.](https://arxiv.org/pdf/2006.06676.pdf): Paper published for the release of StyleGAN2-ADA.\n","*   [Official implementation of StyleGAN2-ADA](https://github.com/NVlabs/stylegan2-ada)\n","*   [StyleGAN v2: notes on training and latent space exploration](https://towardsdatascience.com/stylegan-v2-notes-on-training-and-latent-space-exploration-e51cf96584b3): Interesting article from Toward Data Science"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"Stylegan2-ada_de_curto_and_de_zarza.ipynb","provenance":[{"file_id":"https://github.com/ArthurFDLR/GANightSky/blob/main/GANightSky.ipynb","timestamp":1640369616502}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}